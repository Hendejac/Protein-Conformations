{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import MDAnalysis as mda \n",
    "import matplotlib.pyplot as plt\n",
    "from MDAnalysis.analysis import align\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gc\n",
    "import glob as g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths, pH, and CRD Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pH range \n",
    "pH = \"7.0\"\n",
    "# Location of PSF and DCD\n",
    "path1  = \"/data/jackh/plasmepsin/apo_plasmepsin/run\"\n",
    "path2  = \"/data/jackh/plasmepsin/holo_plasmepsin/run\"\n",
    "direc = \"stage\"\n",
    "# Name of apo psf and initial crds \n",
    "psf1 = '{}/plasmepsin.psf'.format(path1)\n",
    "crd1 = '{}/plasmepsin.crd'.format(path1)\n",
    "psf2 = '{}/1sme.psf'.format(path2)\n",
    "crd2 = '{}/1sme.crd'.format(path2)\n",
    "# Stage Ranges \n",
    "sstage1 = 61\n",
    "lstage1 = 65\n",
    "sstage2 = 41\n",
    "lstage2 = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Frames and extract portion of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Remaking Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_aligner(psf, crd, sstage, lstage, path, direc, skip, o_name='test'):\n",
    "    '''\n",
    "    Libraries Needed: MDAnalysis as mda, Glob as g, and from MDAnalysis.analysis import align, os\n",
    "    psf, for current system \n",
    "    crd, for current system\n",
    "    sstage, start stage\n",
    "    lstage, last stage\n",
    "    '''\n",
    "    ref = mda.Universe(psf, crd, format='CRD')\n",
    "    out_selection = ref.select_atoms(\"protein\")\n",
    "    other_selection  = ref.select_atoms(\"protein\")\n",
    "    with mda.Writer('pdb_for_coloring.pdb', other_selection.n_atoms) as o:\n",
    "        o.write(other_selection)\n",
    "    with mda.Writer('check.pdb', out_selection.n_atoms) as o:\n",
    "        o.write(out_selection)\n",
    "    with mda.Writer('{}.dcd'.format(o_name), out_selection.n_atoms) as w:\n",
    "        frame = 0\n",
    "        for stage in range(sstage, lstage+1):\n",
    "            dcd = g.glob('{}/{}{}/*ph{}*dcd*'.format(path, direc, stage, pH))[0]\n",
    "            u = mda.Universe(psf, dcd, format='DCD')\n",
    "            alignment = align.AlignTraj(u, ref, filename='align.dcd', select=\"name C CA N O\")\n",
    "            alignment.run()\n",
    "            aligned = mda.Universe(psf, 'align.dcd', format='DCD')\n",
    "            selection = aligned.select_atoms('protein')\n",
    "            for ts in aligned.trajectory[::skip]:\n",
    "                w.write(selection)\n",
    "                frame += 1\n",
    "            os.remove('align.dcd')\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from Apo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:864: DeprecationWarning: Using the last letter of the segid for the chainID is now deprecated and will be changed in 2.0. In 2.0, the chainID attribute will be used if it exists, or a placeholder value.\n",
      "  \"exists, or a placeholder value.\", DeprecationWarning)\n",
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:722: UserWarning: Unit cell dimensions not found. CRYST1 record set to unitary values.\n",
      "  warnings.warn(\"Unit cell dimensions not found. \"\n",
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:1032: UserWarning: Found no information for attr: 'altLocs' Using default value of ' '\n",
      "  \"\".format(attrname, default))\n",
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:1032: UserWarning: Found no information for attr: 'icodes' Using default value of ' '\n",
      "  \"\".format(attrname, default))\n",
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:1032: UserWarning: Found no information for attr: 'occupancies' Using default value of '1.0'\n",
      "  \"\".format(attrname, default))\n",
      "/home/jackh/Software/anaconda3/lib/python3.7/site-packages/MDAnalysis/coordinates/PDB.py:1032: UserWarning: Found no information for attr: 'tempfactors' Using default value of '0.0'\n",
      "  \"\".format(attrname, default))\n"
     ]
    }
   ],
   "source": [
    "traj_aligner(psf1, crd1, sstage1, lstage1, path1, direc, 10, o_name='apo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data from Holo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traj_aligner(psf2, crd2, sstage2, lstage2, path2, direc, 10, o_name='holo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new Universes for Mutant and Wild Type Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "apo  = mda.Universe('check.pdb', 'apo.dcd', format='DCD')\n",
    "holo = mda.Universe('check.pdb', 'holo.dcd', format='DCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Apo  Data Points: 250\n",
      "Number of Holo Data Points: 200\n"
     ]
    }
   ],
   "source": [
    "print('Number of Apo  Data Points: {}'.format(len(apo.trajectory)))\n",
    "print('Number of Holo Data Points: {}'.format(len(holo.trajectory)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Selections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = 'protein and name CA'\n",
    "apo_select = apo.select_atoms(selection)\n",
    "holo_select = holo.select_atoms(selection)\n",
    "print('Number of Atoms in apo Selection: {}'.format(len(apo_select)))\n",
    "print('Number of Atoms in holo Selection: {}'.format(len(holo_select)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Data for the Apo State and Create a  Labeled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apo_data = []\n",
    "for ts in apo.trajectory:\n",
    "    all_coors = []\n",
    "    coors = apo_select.positions\n",
    "    for three in coors:\n",
    "        for one in three:\n",
    "            all_coors.append(one)\n",
    "    apo_data.append(all_coors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apo = pd.DataFrame(apo_data)\n",
    "df_apo['label'] = pd.Series('apo', index=df_apo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data for the Holo State and Create Labeled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holo_data = []\n",
    "for ts in holo.trajectory:\n",
    "    all_coors = []\n",
    "    coors = holo_select.positions\n",
    "    for three in coors:\n",
    "        for one in three:\n",
    "            all_coors.append(one)\n",
    "    holo_data.append(all_coors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holo = pd.DataFrame(holo_data)\n",
    "df_holo['label'] = pd.Series('holo', index=df_holo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_and_test(df1, df2, random_seed, label='mut', train_test_split=0.75):\n",
    "    df_mod = pd.DataFrame()\n",
    "    df_sta = pd.DataFrame()\n",
    "    remove_n = 0\n",
    "    if len(df1) > len(df2):\n",
    "        df_mod = df1\n",
    "        df_sta = df2\n",
    "        remove_n = len(df1) - len(df2)\n",
    "    else:\n",
    "        df_mod = df2\n",
    "        df_sta = df1\n",
    "        remove_n = len(df2) - len(df1)\n",
    "    print(remove_n)\n",
    "    drop_indices = np.random.choice(df_mod.index, remove_n, replace=False)\n",
    "    df_mod = df_mod.drop(drop_indices)\n",
    "    split = math.ceil(len(df_sta) * 0.75)\n",
    "    df_mod.sample(frac=1).reset_index(drop=True)\n",
    "    df_sta.sample(frac=1)\n",
    "    df_mod_train = df_mod[:split]\n",
    "    df_mod_test  = df_mod[split:]\n",
    "    df_sta_train = df_sta[:split]\n",
    "    df_sta_test  = df_sta[split:]\n",
    "    df_mod_train = df_mod_train.append(df_sta_train)\n",
    "    df_mod_test  = df_mod_test.append(df_sta_test)\n",
    "    df_mod_train = df_mod_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_mod_test  = df_mod_test.sample(frac=1).reset_index(drop=True)\n",
    "    # Factorize Values for Specific label Types\n",
    "    df_mod_train['num_label'] = [0 if x is label else 1 for x in df_mod_train['label']]\n",
    "    df_mod_test['num_label']  = [0 if x is label else 1 for x in df_mod_test['label']]\n",
    "    return df_mod_train, df_mod_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = create_train_and_test(df_apo, df_holo, random_seed=42, label='apo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train.columns[:-2] # Don't Want the Labels Column\n",
    "labels   = df_train['num_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Model Using the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_jobs=2, random_state=42, n_estimators=1000)\n",
    "rf_clf.fit(df_train[features],  labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Model on the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_clf.predict(df_test[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a Look at the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 10 Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the Confidence of the Label Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.predict_proba(df_test[features])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the First 10 Label from the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "for actual, predict in zip(df_test['num_label'], predictions):\n",
    "    if actual == predict:\n",
    "        num_correct += 1 \n",
    "print('Classifier Success Rate on Test Set: {0:0.2%}'.format(num_correct/len(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a list of the features and their importance scores \n",
    "output = list(zip(df_train[features], rf_clf.feature_importances_))\n",
    "\n",
    "# convert list of tuples to a a list of lists \n",
    "output = [list(temp) for temp in output]\n",
    "\n",
    "sorted_output = sorted(output,key=lambda l:l[1], reverse=True)\n",
    "\n",
    "plt.close('all')\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1)\n",
    "fig.set_facecolor('white')\n",
    "axes.set_ylabel('Feature Importance')\n",
    "axes.set_xlabel('Features')\n",
    "axes.spines['right'].set_visible(False)\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.yaxis.set_ticks_position('left')\n",
    "axes.xaxis.set_ticks_position('bottom')\n",
    "axes.tick_params(direction='out')\n",
    "\n",
    "xmax = 200\n",
    "axes.plot([i for i in range(xmax)], [temp[1] for i, temp in enumerate(sorted_output) if i < xmax],'k.', clip_on = False)\n",
    "plt.show()\n",
    "\n",
    "rate_of_change = [sorted_output[x][1] - sorted_output[x-1][1] for x in range(1, len(output))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Colored PDB Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Residues, because of alpha CA position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important Alpha Carbons\n",
    "important_residues = []\n",
    "importance_for_residues = []\n",
    "cutoff = 0.00\n",
    "count = 0\n",
    "# if residue doesn't start at one include off shift\n",
    "shift = 14\n",
    "for i in range(int(len(output))):\n",
    "    if (i+1) % 3 == 0:\n",
    "        count += 1\n",
    "        if output[i][1] > cutoff or output[i-1][1] > cutoff or output[i-2][1] > cutoff: \n",
    "            all_importance = [output[i][1], output[i-1][1], output[i-2][1]]\n",
    "            importance_for_residues.append(max(all_importance))\n",
    "            important_residues.append(count+shift)\n",
    "            #print(count)\n",
    "print(important_residues)\n",
    "#print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Colored PDB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# Atoms: {}'.format(len(apo_select)))\n",
    "print('# Important Atoms: {}'.format(len(important_residues)))\n",
    "print('# Percent Important: {0:0.2f}%'.format((len(important_residues)/len(apo_select))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb for coloring\n",
    "flag = 0\n",
    "with open(\"importance_by_residues.pdb\", \"w\") as o:\n",
    "    with open(\"check.pdb\", 'r') as f:\n",
    "        for line in f:\n",
    "            line.split(' ')\n",
    "            if line.find(\"ATOM\") != -1:\n",
    "                if line.find(\"PROT\") != -1:\n",
    "                    parta = line[0:60]\n",
    "                    partb = line[67:76]\n",
    "                    #print(line[23:31])\n",
    "                    if int(line[23:31]) == important_residues[flag]: # You might need to add a residue buffer here.\n",
    "                        o.write(\"{}{:6.2f}{}\\n\".format(parta,importance_for_residues[flag]/max(importance_for_residues),partb))\n",
    "                        #print(\"{}{:6.2f}{}\\n\".format(parta,importance[flag]/max(importance),partb))\n",
    "                        if line.find(\" O \") != -1 and flag < len(important_residues)-1:\n",
    "                            flag += 1 \n",
    "                    else:\n",
    "                        o.write(\"{}{:6.2f}{}\\n\".format(parta,0.00,partb))\n",
    "    o.write(\"END\\n\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Garbage Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm apo.dcd')\n",
    "os.system('rm holo.dcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
